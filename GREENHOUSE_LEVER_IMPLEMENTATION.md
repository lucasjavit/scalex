# ImplementaÃ§Ã£o Greenhouse & Lever - Scraping de Vagas

**Data**: 2025-11-07
**Status**: âœ… ImplementaÃ§Ã£o Completa

---

## ğŸ“‹ RESUMO DA IMPLEMENTAÃ‡ÃƒO

Sistema completo de scraping de vagas remotas de empresas que usam **Greenhouse** e **Lever** como ATS (Applicant Tracking Systems).

### âœ… O que foi implementado:

1. **Backend (NestJS)**:
   - âœ… `GreenhouseScraperService` (jÃ¡ existia, otimizado)
   - âœ… `LeverScraperService` (novo)
   - âœ… ConfiguraÃ§Ã£o de empresas (`greenhouse-companies.ts`, `lever-companies.ts`)
   - âœ… Endpoints REST (`/scrape-greenhouse`, `/scrape-lever`, `/scrape-all`)
   - âœ… Migration para desabilitar empresas individuais do BD
   - âœ… IntegraÃ§Ã£o no mÃ³dulo NestJS

2. **Frontend (React)**:
   - âœ… BotÃµes de seleÃ§Ã£o de fonte (Todos / Greenhouse / Lever)
   - âœ… MÃ©todos no `jobsService.js`
   - âœ… Interface atualizada na `JobsPage.jsx`

---

## ğŸ—ï¸ ARQUITETURA

### **Fluxo de Scraping**

```
User â†’ Frontend â†’ Backend API â†’ Scraper Service â†’ External APIs â†’ Redis Cache â†’ Frontend
```

### **Estrutura de Arquivos**

```
back-end/
â”œâ”€â”€ src/modules/remote-jobs/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ greenhouse-companies.ts  âœ… 45+ empresas Greenhouse
â”‚   â”‚   â””â”€â”€ lever-companies.ts       âœ… 45+ empresas Lever
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”œâ”€â”€ base-scraper.service.ts
â”‚   â”‚   â”œâ”€â”€ generic-scraper.service.ts
â”‚   â”‚   â”œâ”€â”€ greenhouse-scraper.service.ts  âœ… Implementado
â”‚   â”‚   â””â”€â”€ lever-scraper.service.ts       âœ… NOVO
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ job-board-aggregator.service.ts  âœ… Atualizado
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â””â”€â”€ job-board.controller.ts         âœ… Novos endpoints
â”‚   â””â”€â”€ remote-jobs.module.ts                âœ… Providers registrados

front-end/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ jobsService.js                   âœ… Novos mÃ©todos
â”‚   â””â”€â”€ modules/remote-jobs/pages/
â”‚       â””â”€â”€ JobsPage.jsx                     âœ… Seletor de fonte
```

---

## ğŸ”Œ ENDPOINTS DA API

### 1. **POST /api/remote-jobs/job-boards/scrape-all**
Busca vagas de **TODAS** as fontes (Wellfound, Built In, RemoteYeah, Greenhouse, Lever)

**Response:**
```json
{
  "success": true,
  "message": "Scraping de job boards concluÃ­do e salvo no Redis",
  "data": {
    "total": 500,
    "byPlatform": {
      "wellfound": 25,
      "builtin": 25,
      "remoteyeah": 25,
      "greenhouse": 200,
      "lever": 225
    },
    "errors": []
  }
}
```

### 2. **POST /api/remote-jobs/job-boards/scrape-greenhouse** âœ… NOVO
Busca vagas **APENAS** de empresas Greenhouse

**Response:**
```json
{
  "success": true,
  "message": "Scraping do Greenhouse concluÃ­do e salvo no Redis",
  "data": {
    "total": 200,
    "companies": 45,
    "errors": []
  }
}
```

### 3. **POST /api/remote-jobs/job-boards/scrape-lever** âœ… NOVO
Busca vagas **APENAS** de empresas Lever

**Response:**
```json
{
  "success": true,
  "message": "Scraping do Lever concluÃ­do e salvo no Redis",
  "data": {
    "total": 225,
    "companies": 45,
    "errors": []
  }
}
```

### 4. **GET /api/remote-jobs/job-boards/jobs**
Busca vagas do Redis com filtros

**Query Params:**
- `platform` (string): 'greenhouse', 'lever', ou vazio para todos
- `page` (number): nÃºmero da pÃ¡gina
- `limit` (number): itens por pÃ¡gina
- `remote` (boolean): apenas remotas
- `seniority` (string): 'junior', 'mid', 'senior', etc
- `employmentType` (string): 'full-time', 'part-time', etc

**Response:**
```json
{
  "success": true,
  "jobs": [...],
  "total": 200,
  "page": 1,
  "limit": 20,
  "totalPages": 10
}
```

---

## ğŸ¢ EMPRESAS CONFIGURADAS

### **Greenhouse (45+ empresas)**

**Tech Giants:**
- GitLab, Discord, Reddit, Dropbox, Roblox

**Remote-First:**
- Automattic (WordPress), Zapier, DuckDuckGo, Buffer, HashiCorp

**Crypto/Web3:**
- Coinbase, OpenSea, Alchemy

**SaaS/B2B:**
- Notion, Canva, Airtable, Miro, Grammarly, Loom

**FinTech:**
- Stripe, Plaid, Brex, Ramp

**E-commerce:**
- Shopify, Etsy, Faire

**Dev Tools:**
- GitHub, Vercel, Netlify, Render

**Data/Analytics:**
- Snowflake, Databricks, Segment, Amplitude

**Enterprise:**
- Slack, Atlassian, Asana, Monday

**Travel:**
- Airbnb, Booking

**Others:**
- Spotify, Twitch, Peloton

### **Lever (45+ empresas)**

**Tech Giants:**
- Netflix, Uber, Lever (prÃ³prio)

**Crypto/Web3:**
- Coinbase, Binance, Kraken, Gemini, Circle, Chainalysis

**FinTech:**
- Stripe

**LATAM:**
- Yuno, Clip (Payclip), Kavak, Bitso, Kushki, Rappi

**Social:**
- Reddit, Duolingo

**Data/Analytics:**
- Databricks, Snowflake, MongoDB, Elastic, Datadog

**Dev Tools:**
- GitLab, Figma

**Design:**
- Canva, Notion

**Others:**
- Workato, Miro, Grammarly, Loom, Airtable, Segment, Amplitude, Plaid, Brex, Ramp, HashiCorp, Vercel, Netlify, Render, Fly.io

---

## âš™ï¸ COMO FUNCIONA

### **1. Backend - Greenhouse Scraper**

```typescript
// Para cada empresa na lista:
const url = `https://boards-api.greenhouse.io/v1/boards/${company}/jobs`;

// Busca jobs
const response = await axios.get(url);
const jobs = response.data.jobs;

// Filtra apenas remotas
const remoteJobs = jobs.filter(job =>
  job.location.name.toLowerCase().includes('remote')
);

// Transforma em formato padrÃ£o
return remoteJobs.map(job => ({
  externalId: `greenhouse-${company}-${job.id}`,
  platform: 'greenhouse',
  title: job.title,
  location: job.location.name,
  externalUrl: job.absolute_url,
  // ...
}));
```

### **2. Backend - Lever Scraper**

```typescript
// Para cada empresa na lista:
const url = `https://api.lever.co/v0/postings/${company}?mode=json`;

// Busca jobs
const response = await axios.get(url);
const jobs = response.data; // Array direto

// Filtra apenas remotas
const remoteJobs = jobs.filter(job =>
  job.categories?.location?.toLowerCase().includes('remote')
);

// Transforma em formato padrÃ£o
return remoteJobs.map(job => ({
  externalId: `lever-${company}-${job.id}`,
  platform: 'lever',
  title: job.text,
  location: job.categories.location,
  externalUrl: job.hostedUrl,
  // ...
}));
```

### **3. Rate Limiting & Batching**

Ambos os scrapers usam:
- **Batch processing**: 5 empresas em paralelo
- **Delay entre batches**: 500ms
- **Timeout por requisiÃ§Ã£o**: 10s
- **Tratamento de erros**: Continue on fail

### **4. Cache (Redis)**

Todas as vagas sÃ£o salvas no Redis com **TTL de 30 minutos**:

```
jobs:all          -> Todas as vagas (sobrescrito por fonte)
jobs:greenhouse   -> Apenas Greenhouse
jobs:lever        -> Apenas Lever
jobs:platform:X   -> EspecÃ­fico por plataforma
```

---

## ğŸ¨ INTERFACE DO USUÃRIO

### **BotÃµes de SeleÃ§Ã£o de Fonte**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸŒ Vagas Remotas                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                              â”‚
â”‚  Buscar vagas de:                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ âœ“ ğŸŒ Todosâ”‚ â”‚ ğŸ¢ Greenhouseâ”‚ â”‚ âš™ï¸ Leverâ”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                              â”‚
â”‚  [ğŸ”„ Atualizar Vagas]                       â”‚
â”‚                                              â”‚
â”‚  Todas as vagas remotas de Greenhouse,      â”‚
â”‚  Lever e agregadores                        â”‚
â”‚                                              â”‚
â”‚  ğŸ“Š 500 vagas encontradas                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Estados dos BotÃµes**

1. **"Todos"** (padrÃ£o):
   - BotÃ£o azul ativo
   - Busca: Wellfound, Built In, RemoteYeah, Greenhouse, Lever
   - DescriÃ§Ã£o: "Todas as vagas remotas de Greenhouse, Lever e agregadores"

2. **"Greenhouse"**:
   - BotÃ£o azul ativo
   - Busca: Apenas Greenhouse (45+ empresas)
   - DescriÃ§Ã£o: "Vagas remotas de 45+ empresas que usam Greenhouse: GitLab, Coinbase, Airbnb, Stripe e mais"

3. **"Lever"**:
   - BotÃ£o azul ativo
   - Busca: Apenas Lever (45+ empresas)
   - DescriÃ§Ã£o: "Vagas remotas de 45+ empresas que usam Lever: Netflix, Uber, Reddit, MongoDB e mais"

---

## ğŸ“Š RESULTADOS ESPERADOS

### **Antes da ImplementaÃ§Ã£o:**
```
Scrape All â†’ 75 vagas
â”œâ”€ Wellfound: 25 vagas âœ…
â”œâ”€ Built In: 25 vagas âœ…
â”œâ”€ RemoteYeah: 25 vagas âœ…
â”œâ”€ Greenhouse: 0 vagas âŒ
â””â”€ Lever: 0 vagas âŒ
```

### **Depois da ImplementaÃ§Ã£o:**
```
Scrape All â†’ 500-1000 vagas
â”œâ”€ Wellfound: 25 vagas âœ…
â”œâ”€ Built In: 25 vagas âœ…
â”œâ”€ RemoteYeah: 25 vagas âœ…
â”œâ”€ Greenhouse: 200-400 vagas âœ…
â””â”€ Lever: 200-400 vagas âœ…

Scrape Greenhouse Only â†’ 200-400 vagas âœ…
Scrape Lever Only â†’ 200-400 vagas âœ…
```

---

## ğŸš€ COMO TESTAR

### **1. Backend**

```bash
# Iniciar servidor
cd back-end
npm run dev

# Testar endpoints
curl -X POST http://localhost:3000/api/remote-jobs/job-boards/scrape-greenhouse
curl -X POST http://localhost:3000/api/remote-jobs/job-boards/scrape-lever
curl http://localhost:3000/api/remote-jobs/job-boards/jobs?platform=greenhouse
```

### **2. Frontend**

```bash
# Iniciar dev server
cd front-end
npm run dev

# Acessar: http://localhost:5173/jobs

# Testar:
1. Clicar em "ğŸ¢ Greenhouse"
2. Clicar em "ğŸ”„ Atualizar Vagas"
3. Aguardar scraping (30-60s)
4. Ver vagas carregadas
5. Repetir para "âš™ï¸ Lever"
```

---

## ğŸ“ NOTAS TÃ‰CNICAS

### **Por que desabilitamos as empresas individuais do BD?**

Anteriormente, tÃ­nhamos 41 empresas Lever/Greenhouse no banco de dados com URLs company-specific. **Todas retornavam 404** porque:
1. As pÃ¡ginas nÃ£o existem
2. As empresas nÃ£o usam mais esses ATSs publicamente
3. As URLs estavam erradas

**SoluÃ§Ã£o:** Criar scrapers dedicados que iteram sobre listas curadas de empresas verificadas, permitindo:
- Controle total sobre quais empresas rastrear
- FÃ¡cil adiÃ§Ã£o/remoÃ§Ã£o de empresas
- Melhor tratamento de erros
- EstatÃ­sticas por empresa

### **APIs vs Web Scraping**

- **Greenhouse**: Usa API REST oficial (`boards-api.greenhouse.io`)
- **Lever**: Usa API REST oficial (`api.lever.co/v0/postings`)
- Ambos retornam JSON estruturado
- NÃ£o requerem autenticaÃ§Ã£o para endpoints pÃºblicos
- Rate limits liberais (desde que respeitemos delays)

### **Performance**

- **Greenhouse**: ~45 empresas Ã— 500ms = ~22s
- **Lever**: ~45 empresas Ã— 500ms = ~22s
- **Total (ambos)**: ~45s para 400-800 vagas
- Cache Redis: 30 minutos TTL

### **Escalabilidade**

Para adicionar mais empresas:
1. Editar `greenhouse-companies.ts` ou `lever-companies.ts`
2. Adicionar novo objeto `{ slug, name, description }`
3. Rebuild e deploy
4. Scraper automaticamente incluirÃ¡ a nova empresa

---

## ğŸ› TROUBLESHOOTING

### **Erro: "No migrations are pending"**
- A migration jÃ¡ foi executada
- Execute o SQL manualmente se necessÃ¡rio

### **Erro: Nenhuma vaga encontrada**
- Verifique se Redis estÃ¡ rodando
- Teste endpoints individualmente
- Confira logs do backend

### **Erro: Build fails**
- Ignore erros do Angular CLI global
- Use `node_modules/.bin/nest build`

---

## âœ… CHECKLIST DE IMPLEMENTAÃ‡ÃƒO

- [x] Migration para desabilitar empresas individuais
- [x] `lever-companies.ts` config criado
- [x] `LeverScraperService` implementado
- [x] Endpoints `/scrape-greenhouse` e `/scrape-lever` adicionados
- [x] `fetchAndStoreGreenhouseJobs()` no aggregator
- [x] `fetchAndStoreLeverJobs()` no aggregator
- [x] `LeverScraperService` registrado no module
- [x] `triggerGreenhouseScraping()` no jobsService.js
- [x] `triggerLeverScraping()` no jobsService.js
- [x] BotÃµes de seleÃ§Ã£o de fonte no JobsPage
- [x] DocumentaÃ§Ã£o completa

---

**Ãšltima atualizaÃ§Ã£o**: 2025-11-07
**Desenvolvedor**: Claude + Lucas
